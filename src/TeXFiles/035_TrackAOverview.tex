%=============================================================================
\chapter{Track A Overview: Workflow Automation and Infrastructure R\&D}
\label{ch:TrackAOverview}
%=============================================================================
% Page budget: 2 pages (Pages 11--12)
% Track A is presented as an independent engineering track focused on
% workflow automation, infrastructure experimentation, and interoperability
% research. No architectural or runtime dependency on LangGraph is assumed.
%=============================================================================

This chapter provides an overview of Track A - workflow automation and
infrastructure R\&D. This track should be seen as an independent engineering effort
with its own objectives, scope, and architecture. The focus was on integrating
AI-enabled capabilities into existing systems through deterministic workflows
and evaluating infrastructure patterns for serving and operating such systems.

%=============================================================================
\section{Track A Goals and Scope}
\label{sec:TrackA_Goals}
%=============================================================================

The primary goal of Track A was to explore practical approaches for integrating
AI-assisted functionality into existing enterprise systems while maintaining
operational safety, traceability, and predictability.

Track A addressed three problem areas:

\begin{itemize}
      \item \textbf{Workflow automation for enterprise systems}: integrating
            AI-assisted steps into ERP-related processes using deterministic
            orchestration.
      \item \textbf{Infrastructure experimentation for model serving}: evaluating
            local deployment patterns and comparing serving approaches from an
            operational perspective.
      \item \textbf{Tooling interoperability research}: experimenting with MCP
            as a standardized interface for exposing tools, resources, and
            prompts to AI systems.
\end{itemize}

The intent was exploratory and evaluative. The emphasis was on understanding
trade-offs, constraints, and failure modes rather than building a complete
production system.

\subsection{Scope}
\label{subsec:TrackA_ExplicitScope}

Track A covered the following activities:
\begin{itemize}
      \item AI-enabled workflow automation using \texttt{n8n}, integrated with
            ERP processes.
      \item Evaluation of local model serving and deployment options, including
            performance and operational considerations.
      \item Experimental investigation of MCP for tool and context
            interoperability across AI systems.
\end{itemize}

\subsection{Out-of-Scope}
\label{subsec:TrackA_OutOfScope}

The following were out of scope for Track A:
\begin{itemize}
      \item Agent orchestration, stateful reasoning, or human-in-the-loop
            control via LangGraph.
      \item Agent lifecycle management, governance, or observability mechanisms
            from Track B.
      \item Tight coupling between workflow automation and agent-based systems.
\end{itemize}

This separation keeps Track A conclusions applicable to workflow and
infrastructure design without assuming an agent-based execution model.

%=============================================================================
\section{Track A Architecture Overview}
\label{sec:TrackA_Architecture}
%=============================================================================

Track A used a modular, loosely coupled architecture that allowed components
to be evaluated in isolation. The design supported experimentation while
minimizing unintended side effects on existing systems.

The architecture consists of four conceptual layers:

\begin{enumerate}
      \item \textbf{Enterprise system layer}: existing ERP systems and business
            processes that act as event sources or consumers of automated actions.
      \item \textbf{Workflow orchestration layer}: implemented using \texttt{n8n},
            handling deterministic execution, conditional branching, retries,
            and error handling.
      \item \textbf{Infrastructure and serving sandbox}: used to evaluate local
            and enterprise model serving patterns under controlled conditions.
      \item \textbf{Interoperability research sandbox}: where MCP was explored
            as an interface for exposing tools and context to AI components.
\end{enumerate}

These layers were kept independent to allow focused evaluation. Workflow
orchestration was treated as a deterministic control plane, while
infrastructure and interoperability experiments ran in isolation from
production workflows.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=0.6\textwidth]{Figures/overviewA.png}
      \caption{Track A main components}
      \label{fig:track_a_context}
\end{figure}

This separation enabled:
\begin{itemize}
      \item clear reasoning about failure modes and recovery in automated
            workflows,
      \item controlled evaluation of serving options without production risk,
      \item exploratory investigation of interoperability without constraining
            later decisions.
\end{itemize}